#!/usr/bin/env python3
"""
Smart Form Fill API - Field-by-Field Form Filling
OPTIMIZED VERSION with Performance Enhancements
"""
# %%
import os
import asyncio
from functools import lru_cache
from contextlib import asynccontextmanager
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, Query, Depends, Request, UploadFile, File, Form, Header
from fastapi import Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from httpcore import request
from pydantic import BaseModel, HttpUrl
from typing import Dict, Any, List, Optional
from datetime import datetime
# Configure logger first
from app.utils.logger import configure_logger
configure_logger()

from loguru import logger
from sqlalchemy.orm import Session
import io
from sqlalchemy import func
import time
import PyPDF2
import docx2txt

# Import auth components
from database import get_db
from models import User, UserSession

# Import form filling services
from app.services.form_filler_optimized import OptimizedFormFiller

# Import database-based extractors
from app.services.resume_extractor_optimized import ResumeExtractorOptimized
from app.services.personal_info_extractor_optimized import PersonalInfoExtractorOptimized
from app.services.document_service import DocumentService
from app.models.document_models import ResumeDocument, PersonalInfoDocument
from app.utils.text_extractor import extract_text_from_file

# Import embedding service
from app.services.embedding_service import EmbeddingService

# Import LLM service
from app.services.llm_service import SmartLLMService

# URL tracking endpoints (simplified for frontend compatibility)
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifecycle management"""
    logger.info("üöÄ Starting Smart Form Fill API (OPTIMIZED)")
    
    # Create tables
    from create_tables import create_tables
    create_tables(DATABASE_URL)
    
    # Pre-warm the singletons
    try:
        logger.info("üîß Pre-warming services...")
        get_document_service()
        get_resume_extractor()
        get_personal_info_extractor()
        get_form_filler()
        get_smart_llm_service()
        get_embedding_service()
        logger.info("‚úÖ All services pre-warmed successfully")
    except Exception as e:
        logger.error(f"‚ùå Service pre-warming failed: {e}")

# Load environment variables
# For Railway deployment, check if we're in Railway environment first
# If not in Railway, then load .env file
if not os.getenv("RAILWAY_ENVIRONMENT"):
    load_dotenv()

# Get environment variables
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
# For Railway deployment, force the correct DATABASE_URL 
if os.getenv("RAILWAY_ENVIRONMENT"):
    DATABASE_URL = "postgresql://postgres:OZNHVfQlRwGhcUBFmkVluOzTonqTpIKa@interchange.proxy.rlwy.net:30153/railway"
    
    # Force Railway Redis URL for production
    REDIS_URL = "redis://default:bzjztpnzvaybwVlISyGxYSNUnFAmgtAM@shuttle.proxy.rlwy.net:46918"
    
    print(f"üöÇ Railway: Using hardcoded DATABASE_URL")
    print(f"üî¥ Railway: Using hardcoded REDIS_URL")
else:
    DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://postgres:OZNHVfQlRwGhcUBFmkVluOzTonqTpIKa@interchange.proxy.rlwy.net:30153/railway")
    REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379")
PORT = int(os.getenv("PORT", "8000"))
ALLOWED_HOSTS = os.getenv("ALLOWED_HOSTS", "localhost,127.0.0.1").split(',')

# Debug logging for Railway deployment
if os.getenv("RAILWAY_ENVIRONMENT"):
    print(f"üöÇ Railway Environment: {os.getenv('RAILWAY_ENVIRONMENT')}")
    print(f"üîë OPENAI_API_KEY: {'‚úÖ SET' if OPENAI_API_KEY else '‚ùå NOT SET'}")
    print(f"üóÑÔ∏è DATABASE_URL: {'‚úÖ SET' if DATABASE_URL else '‚ùå NOT SET'}")
    print(f"üî¥ REDIS_URL: {'‚úÖ SET' if REDIS_URL else '‚ùå NOT SET'}")
    
    # Debug: Show the actual DATABASE_URL being used
    print(f"üîç Raw DATABASE_URL from env: {repr(os.getenv('DATABASE_URL'))}")
    print(f"üîç Final DATABASE_URL variable: {repr(DATABASE_URL)}")
    
    # Debug Redis configuration
    print(f"üîç Raw REDIS_URL from env: {repr(os.getenv('REDIS_URL'))}")
    print(f"üîç Final REDIS_URL variable: {REDIS_URL.split('@')[0] if '@' in REDIS_URL else 'Invalid URL'}@[HIDDEN]")
    
    # Log DATABASE_URL format without exposing credentials
    if DATABASE_URL:
        # Extract host info for debugging
        try:
            from urllib.parse import urlparse
            parsed = urlparse(DATABASE_URL)
            print(f"üîç Database Host: {parsed.hostname}")
            print(f"üîç Database Port: {parsed.port}")
            print(f"üîç Database Name: {parsed.path.lstrip('/')}")
        except Exception as e:
            print(f"‚ö†Ô∏è Could not parse DATABASE_URL: {e}")

if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY environment variable is required")

# Test Redis connection and capabilities
try:
    import redis
    redis_client = redis.from_url(REDIS_URL)
    redis_client.ping()
    print("‚úÖ Redis connection successful")
    
    # Get Redis server info
    try:
        info = redis_client.info()
        print(f"üîç Redis version: {info.get('redis_version', 'unknown')}")
        print(f"üîç Redis mode: {info.get('redis_mode', 'unknown')}")
    except Exception as e:
        print(f"‚ö†Ô∏è Could not get Redis info: {e}")
    
    # Check for RediSearch capability
    try:
        redis_client.execute_command("FT._LIST")
        print("‚úÖ RediSearch module available - full vector search enabled")
    except redis.exceptions.ResponseError as e:
        print(f"‚ö†Ô∏è RediSearch module not available: {e}")
        print("   üìù Note: Vector search will use fallback method or Pinecone")
        print("   üí° Railway provides standard Redis, not Redis Stack")
        
        # Check what modules are available
        try:
            modules = redis_client.execute_command("MODULE", "LIST")
            print(f"üîç Available modules: {modules}")
        except Exception:
            print("üîç No additional modules available")
            
except Exception as e:
    print(f"‚ùå Redis connection failed: {e}")
    print("‚ö†Ô∏è Redis features will be limited")

# Check Pinecone availability
pinecone_api_key = os.getenv("PINECONE_API_KEY")
if pinecone_api_key:
    try:
        from app.services.pinecone_vector_store import PineconeVectorStore
        print("‚úÖ Pinecone API key found - production vector search enabled")
        print("   üöÄ Vector search will use Pinecone (fast & scalable)")
    except ImportError as e:
        print(f"‚ö†Ô∏è Pinecone not available: {e}")
        print("   üìù Install with: pip install pinecone-client")
else:
    print("‚ö†Ô∏è PINECONE_API_KEY not set - using Redis fallback")
    print("   üí° Add PINECONE_API_KEY to Railway dashboard for optimal performance")

# Alternative: Check if PostgreSQL has pgvector extension
try:
    from sqlalchemy import create_engine, text
    temp_engine = create_engine(DATABASE_URL)
    with temp_engine.connect() as conn:
        result = conn.execute(text("SELECT * FROM pg_available_extensions WHERE name = 'vector'"))
        if result.fetchone():
            print("‚úÖ PostgreSQL pgvector extension available")
            print("   üí° Could use PostgreSQL for vector storage instead of Redis")
        else:
            print("‚ö†Ô∏è PostgreSQL pgvector extension not available")
    temp_engine.dispose()
except Exception as e:
    print(f"üîç Could not check pgvector: {e}")

# Session-based authentication dependency
def get_session_user(db: Session = Depends(get_db), session_id: str = Header(None, alias="Authorization")):
    """
    Dependency to get the current user based on session ID from Authorization header
    Raises HTTPException if session is invalid or expired
    """
    if not session_id:
        raise HTTPException(status_code=401, detail="No session ID provided")
    
    # Query the active session
    session = db.query(UserSession).filter(
        UserSession.session_id == session_id,
        UserSession.is_active == True
    ).first()
    
    if not session:
        raise HTTPException(status_code=401, detail="Invalid or expired session")
    
    # Get the associated user
    user = db.query(User).filter(User.id == session.user_id).first()
    if not user:
        raise HTTPException(status_code=401, detail="User not found")
    
    # Update last_used_at timestamp
    session.last_used_at = datetime.utcnow()
    db.commit()
    
    return user

# üöÄ PERFORMANCE OPTIMIZATION: Global singletons with proper lifecycle management
_resume_extractor = None
_personal_info_extractor = None
_form_filler = None
_document_service = None

@lru_cache(maxsize=1)
def get_document_service():
    """Cached document service singleton"""
    global _document_service
    if _document_service is None:
        _document_service = DocumentService(DATABASE_URL)
    return _document_service

def get_resume_extractor():
    """Resume extractor singleton (cache disabled for debugging)"""
    global _resume_extractor
    # Force recreation for debugging
    _resume_extractor = ResumeExtractorOptimized(
        openai_api_key=OPENAI_API_KEY,
        database_url=DATABASE_URL,
        use_hf_fallback=True
    )
    # Clear any existing cache to ensure fresh start
    _resume_extractor.clear_cache()
    return _resume_extractor

@lru_cache(maxsize=1)
def get_personal_info_extractor():
    """Cached personal info extractor singleton"""
    global _personal_info_extractor
    if _personal_info_extractor is None:
        _personal_info_extractor = PersonalInfoExtractorOptimized(
            openai_api_key=OPENAI_API_KEY,
            database_url=DATABASE_URL,
            use_hf_fallback=True
        )
    return _personal_info_extractor

@lru_cache(maxsize=1)
def get_form_filler():
    """Cached form filler singleton"""
    global _form_filler
    if _form_filler is None:
        _form_filler = OptimizedFormFiller(
            openai_api_key=OPENAI_API_KEY,
            resume_extractor=get_resume_extractor(),
            personal_info_extractor=get_personal_info_extractor(),
            headless=True
        )
    return _form_filler

@lru_cache(maxsize=1)
def get_smart_llm_service():
    """Get Smart LLM service instance"""
    return SmartLLMService(redis_url=REDIS_URL)

@lru_cache(maxsize=1)
def get_embedding_service():
    """Get embedding service instance"""
    return EmbeddingService(redis_url=REDIS_URL, openai_api_key=OPENAI_API_KEY)

# Integrated usage analyzer and simple function tracker imports removed

# Lifecycle management
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifecycle management"""
    logger.info("üöÄ Starting Smart Form Fill API (OPTIMIZED)")
    
    # Pre-warm the singletons
    try:
        logger.info("üîß Pre-warming services...")
        get_document_service()
        get_resume_extractor()
        get_personal_info_extractor()
        get_form_filler()
        get_smart_llm_service()
        get_embedding_service()
        logger.info("‚úÖ All services pre-warmed successfully")
    except Exception as e:
        logger.error(f"‚ùå Service pre-warming failed: {e}")
    
    # Usage analysis removed
    
    yield
    
    # Usage analysis removed
    
    # Cleanup
    logger.info("üõë Shutting down Smart Form Fill API")

# Pydantic models
class ReembedResponse(BaseModel):
    status: str
    message: str
    processing_time: float
    database_info: Dict[str, Any]

class FieldAnswerRequest(BaseModel):
    label: str
    url: str
    user_id: Optional[str] = None  # Optional for demo endpoint
    # Note: user_id is now determined from session authentication for main endpoint, but can be passed for demo

class FieldAnswerResponse(BaseModel):
    answer: str
    data_source: str
    reasoning: str
    status: str
    performance_metrics: Optional[Dict[str, Any]] = None

class TranslationRequest(BaseModel):
    text: str
    source_language: str = "en"  # Default: English
    target_language: str = "ru"  # Default: Russian

class TranslationResponse(BaseModel):
    original_text: str
    translated_text: str
    source_language: str
    target_language: str
    confidence: Optional[float] = None
    status: str

# ============================================================================
# USER AUTHENTICATION MODELS
# ============================================================================

class UserRegister(BaseModel):
    email: str
    password: str

class UserLogin(BaseModel):
    email: str
    password: str

# Note: UserResponse and TokenResponse models removed since JWT auth is disabled

# Initialize FastAPI app with lifecycle management
app = FastAPI(
    title="Smart Form Fill API (OPTIMIZED)",
    description="High-Performance Field-by-Field Intelligent Form Filling",
    version="4.1.0-optimized",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# Custom CORS handling for hybrid scenarios
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.responses import Response

class CustomCORSMiddleware(BaseHTTPMiddleware):
    def __init__(self, app):
        super().__init__(app)
        self.localhost_origins = {
            "http://localhost:5173",
            "http://localhost:3000", 
            "http://127.0.0.1:5173",
            "http://127.0.0.1:3000"
        }
        # Explicit headers list to avoid issues with "*"
        self.allowed_headers = [
            "Accept", "Accept-Language", "Content-Language", "Content-Type",
            "Authorization", "X-Requested-With", "Origin", "DNT", "Cache-Control",
            "User-Agent", "If-Modified-Since", "Keep-Alive", "X-Requested-With",
            "If-None-Match", "X-CSRF-Token", "X-Forwarded-For", "X-Real-IP"
        ]
    
    async def dispatch(self, request, call_next):
        origin = request.headers.get("origin")
        
        # Handle preflight requests
        if request.method == "OPTIONS":
            response = Response()
            if origin in self.localhost_origins:
                # Localhost gets credentials support
                response.headers["Access-Control-Allow-Origin"] = origin
                response.headers["Access-Control-Allow-Credentials"] = "true"
            else:
                # All other origins get universal access
                response.headers["Access-Control-Allow-Origin"] = "*"
            
            response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS"
            response.headers["Access-Control-Allow-Headers"] = ", ".join(self.allowed_headers)
            response.headers["Access-Control-Expose-Headers"] = ", ".join(self.allowed_headers)
            response.headers["Access-Control-Max-Age"] = "86400"  # Cache preflight for 24 hours
            return response
        
        # Process actual request
        response = await call_next(request)
        
        # Add CORS headers to response
        if origin in self.localhost_origins:
            # Localhost gets credentials support
            response.headers["Access-Control-Allow-Origin"] = origin
            response.headers["Access-Control-Allow-Credentials"] = "true"
        else:
            # All other origins get universal access
            response.headers["Access-Control-Allow-Origin"] = "*"
        
        response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS"
        response.headers["Access-Control-Allow-Headers"] = ", ".join(self.allowed_headers)
        response.headers["Access-Control-Expose-Headers"] = ", ".join(self.allowed_headers)
        
        return response

# Add custom CORS middleware
app.add_middleware(CustomCORSMiddleware)

# Add usage analysis middleware (DISABLED)
# from app.middleware.usage_middleware import UsageAnalysisMiddleware
# app.add_middleware(UsageAnalysisMiddleware)

# Deep tracking middleware removed

# URL tracking router removed

# Initialize services
document_service = DocumentService(DATABASE_URL)
embedding_service = EmbeddingService(
    redis_url=REDIS_URL,
    openai_api_key=OPENAI_API_KEY
)

# ============================================================================
# SIMPLIFIED MAIN FIELD ANSWER ENDPOINT (Backend Authorization)
# ============================================================================

@app.post("/api/generate-field-answer", response_model=FieldAnswerResponse)
async def generate_field_answer(
    field_data: FieldAnswerRequest,
    user: User = Depends(get_session_user)
):
    """
    üß† Generate AI answer for form field using Redis Vector Store
    
    Uses 3-tier system: Resume Redis ‚Üí Personal Info Redis ‚Üí LLM Generation
    Auth: Requires valid session
    """
    try:
        # Get Smart LLM service
        llm_service = get_smart_llm_service()
        
        # Generate answer using Redis-powered system
        service_start = time.time()
        result = await llm_service.generate_field_answer(
            field_label=field_data.label,
            user_id=user.id,
            field_context={
                "url": field_data.url,
                "field_type": getattr(field_data, 'field_type', None),
                "field_name": getattr(field_data, 'field_name', None)
            }
        )
        service_time = time.time() - service_start
        
        logger.info(f"‚úÖ Generated answer: '{result['answer']}' (source: {result['data_source']}) in {result['performance_metrics']['processing_time_seconds']:.2f}s")
        
        return FieldAnswerResponse(
            answer=result["answer"],
            data_source=result["data_source"],
            reasoning=result["reasoning"],
            status=result["status"],
            performance_metrics=result["performance_metrics"]
        )
        
    except Exception as e:
        logger.error(f"‚ùå Error generating field answer: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# USER ID VALIDATION ENDPOINT (For Extension Setup)
# ============================================================================

@app.get("/api/validate-user/{user_id}")
async def validate_user_id(user_id: str, db: Session = Depends(get_db)):
    """
    üîç Validate if user_id exists and is active
    Extension can use this to verify user before sending requests
    """
    try:
        user = db.query(User).filter(User.id == user_id, User.is_active == True).first()
        if not user:
            raise HTTPException(status_code=404, detail="User not found or inactive")
        
        return {
            "status": "valid",
            "user_id": user_id,
            "user_type": "registered",
            "email": user.email,
            "message": "User validated successfully"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå User validation failed: {e}")
        raise HTTPException(status_code=500, detail=f"Validation failed: {str(e)}")

# ============================================================================
# SIMPLIFIED USER REGISTRATION (Returns User ID)
# ============================================================================

class SimpleRegisterResponse(BaseModel):
    """
    üìù Simple response for register/login
    Includes user_id and session_id for authentication
    """
    status: str
    user_id: int  # Changed from str to int to match production database
    email: str
    message: str

@app.post("/api/simple/register", response_model=SimpleRegisterResponse)
async def simple_register_user(user_data: UserRegister, db: Session = Depends(get_db)):
    """
    üîê Simplified Registration: Returns user_id directly (no JWT tokens)
    Handles existing users appropriately
    """
    try:
        # Check if user already exists
        existing_user = db.query(User).filter(User.email == user_data.email).first()
        if existing_user:
            if existing_user.is_active:
                logger.info(f"‚ùå Registration failed: User already exists - {user_data.email}")
                raise HTTPException(
                    status_code=409,
                    detail="User already exists. Please login instead."
                )
            else:
                # Reactivate inactive user
                existing_user.is_active = True
                existing_user.set_password(user_data.password)
                db.commit()
                logger.info(f"‚úÖ Reactivated user: {user_data.email} (ID: {existing_user.id})")
                return SimpleRegisterResponse(
                    status="reactivated",
                    user_id=existing_user.id,
                    email=existing_user.email,
                    message="Account reactivated successfully. Please login."
                )
        
        # Create new user with username generated from email
        import re
        username = re.sub(r'[^a-zA-Z0-9_]', '', user_data.email.split('@')[0])
        if not username:
            username = "user"
        
        new_user = User(
            email=user_data.email,
            username=username
        )
        new_user.set_password(user_data.password)
        
        db.add(new_user)
        db.commit()
        db.refresh(new_user)
        
        logger.info(f"‚úÖ New user registered: {user_data.email} (ID: {new_user.id})")
        
        return SimpleRegisterResponse(
            status="registered",
            user_id=new_user.id,
            email=new_user.email,
            message="Registration successful. Please login to continue."
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Registration failed: {e}")
        raise HTTPException(status_code=500, detail="Registration failed. Please try again.")

# ============================================================================
# SIMPLIFIED USER LOGIN (Returns User ID)
# ============================================================================

@app.post("/api/simple/login", response_model=SimpleRegisterResponse)
async def simple_login_user(user_data: UserLogin, db: Session = Depends(get_db)):
    """
    üîê Simplified Login: Returns user_id
    Extension should then call check-and-update endpoint to get/create session
    """
    try:
        # Find user by email
        user = db.query(User).filter(User.email == user_data.email, User.is_active == True).first()
        if not user or not user.verify_password(user_data.password):
            raise HTTPException(status_code=401, detail="Invalid email or password")
        
        logger.info(f"‚úÖ User authenticated: {user_data.email} (ID: {user.id})")
        
        return SimpleRegisterResponse(
            status="authenticated",
            user_id=user.id,
            email=user.email,
            message="Authentication successful - use check-and-update endpoint for session"
        )
    except Exception as e:
        logger.error(f"‚ùå Login failed for {user_data.email}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# ULTRA SIMPLE SESSION MANAGEMENT (Store session_id in DB)
# ============================================================================

class SessionCreateRequest(BaseModel):
    user_id: str
    device_info: Optional[str] = None

class SessionResponse(BaseModel):
    status: str
    session_id: str
    user_id: str
    message: str

class CurrentUserResponse(BaseModel):
    status: str
    user_id: str
    email: str
    session_id: str
    device_info: Optional[str] = None
    created_at: str
    last_used_at: str

@app.post("/api/session/create", response_model=SessionResponse)
async def create_user_session(
    session_request: SessionCreateRequest, 
    db: Session = Depends(get_db)
):
    """
    üîë Create a simple session for user (stores session_id in DB)
    Perfect for browser extensions - no JWT complexity!
    
    Usage:
    1. Register/Login ‚Üí get user_id
    2. Create session ‚Üí get session_id  
    3. Store session_id locally
    4. Use session_id to get current user info
    """
    try:
        # Validate user exists and is active
        user = db.query(User).filter(User.id == session_request.user_id, User.is_active == True).first()
        if not user:
            raise HTTPException(status_code=404, detail=f"User not found or inactive: {session_request.user_id}")
        
        # Create new session
        new_session = UserSession(
            user_id=session_request.user_id,
            device_info=session_request.device_info
        )
        
        db.add(new_session)
        db.commit()
        db.refresh(new_session)
        
        logger.info(f"‚úÖ Session created for user: {user.email} (Session: {new_session.session_id})")
        
        return SessionResponse(
            status="created",
            session_id=new_session.session_id,
            user_id=user.id,
            message="Session created successfully - store this session_id"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Session creation failed: {e}")
        raise HTTPException(status_code=500, detail="Session creation failed")

@app.get("/api/session/current/{session_id}", response_model=CurrentUserResponse)
async def get_current_user_by_session(
    session_id: str,
    db: Session = Depends(get_db)
):
    """
    üë§ Get current user info by session_id (stored in browser extension)
    
    Usage:
    const sessionId = localStorage.getItem('session_id');
    const response = await fetch(`/api/session/current/${sessionId}`);
    const user = await response.json();
    """
    try:
        # Find active session
        session = db.query(UserSession).filter(
            UserSession.session_id == session_id,
            UserSession.is_active == True
        ).first()
        
        if not session:
            raise HTTPException(status_code=404, detail="Session not found or expired")
        
        # Get user details
        user = db.query(User).filter(User.id == session.user_id, User.is_active == True).first()
        if not user:
            raise HTTPException(status_code=404, detail="User not found or inactive")
        
        # Update last used timestamp
        session.last_used_at = func.now()
        db.commit()
        
        logger.info(f"‚úÖ Session accessed: {user.email} (Session: {session_id})")
        
        return CurrentUserResponse(
            status="active",
            user_id=user.id,
            email=user.email,
            session_id=session.session_id,
            device_info=session.device_info,
            created_at=session.created_at.isoformat(),
            last_used_at=session.last_used_at.isoformat()
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Session lookup failed: {e}")
        raise HTTPException(status_code=500, detail="Session lookup failed")

@app.delete("/api/session/{session_id}")
async def delete_user_session(
    session_id: str,
    db: Session = Depends(get_db)
):
    """
    üóëÔ∏è Delete/logout session (deactivate in DB)
    """
    try:
        session = db.query(UserSession).filter(UserSession.session_id == session_id).first()
        if not session:
            raise HTTPException(status_code=404, detail="Session not found")
        
        # Deactivate session instead of deleting
        session.is_active = False
        db.commit()
        
        logger.info(f"‚úÖ Session deactivated: {session_id}")
        
        return {"status": "deactivated", "message": "Session logged out successfully"}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Session deletion failed: {e}")
        raise HTTPException(status_code=500, detail="Session deletion failed")

@app.get("/api/session/list/{user_id}")
async def list_user_sessions(
    user_id: str,
    db: Session = Depends(get_db)
):
    """
    üìã List all active sessions for a user (for session management)
    """
    try:
        # Validate user exists
        user = db.query(User).filter(User.id == user_id, User.is_active == True).first()
        if not user:
            raise HTTPException(status_code=404, detail="User not found")
        
        # Get all active sessions
        sessions = db.query(UserSession).filter(
            UserSession.user_id == user_id,
            UserSession.is_active == True
        ).all()
        
        session_list = []
        for session in sessions:
            session_list.append({
                "session_id": session.session_id,
                "device_info": session.device_info,
                "created_at": session.created_at.isoformat(),
                "last_used_at": session.last_used_at.isoformat()
            })
        
        return {
            "status": "success",
            "user_id": user_id,
            "active_sessions": len(session_list),
            "sessions": session_list
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå List sessions failed: {e}")
        raise HTTPException(status_code=500, detail="Failed to list sessions")

# ============================================================================
# URL TRACKING ENDPOINTS (Simplified for Frontend Compatibility)
# ============================================================================

@app.get("/api/urls/stats/summary")
async def get_url_stats_summary(
    user: User = Depends(get_session_user)
):
    """
    üìä Get URL tracking statistics summary
    Simplified endpoint for frontend compatibility
    """
    try:
        # Return mock data for now since URL tracking is disabled
        return {
            "status": "success",
            "message": "URL stats retrieved successfully",
            "stats": {
                "total_urls": 0,
                "applied": 0,
                "in_progress": 0,
                "not_applied": 0
            },
            "note": "URL tracking feature is currently disabled. This is mock data for frontend compatibility."
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error getting URL stats: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error retrieving URL stats: {str(e)}"
        )

@app.post("/api/urls/save")
async def save_url(
    url_data: dict,
    user: User = Depends(get_session_user)
):
    """
    üíæ Save URL for tracking
    Simplified endpoint for frontend compatibility
    """
    try:
        url = url_data.get("url", "")
        title = url_data.get("title", "Untitled")
        
        logger.info(f"üìå URL save requested: {title} ({url}) for user {user.id}")
        
        # Return success response (no actual saving since feature is disabled)
        return {
            "status": "success",
            "message": "URL saved successfully (mock - tracking disabled)",
            "url": url,
            "title": title,
            "note": "URL tracking feature is currently disabled. This is a mock response for frontend compatibility."
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error saving URL: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error saving URL: {str(e)}"
        )

# ============================================================================
# DOCUMENTS STATUS ENDPOINT (Authentication Required)
# ============================================================================

class DocumentStatusResponse(BaseModel):
    status: str
    documents: Dict[str, Any]
    user_id: int
    message: str

@app.get("/api/v1/documents/status", response_model=DocumentStatusResponse)
async def get_documents_status(
    user: User = Depends(get_session_user)
):
    """
    üìã Get status of user's documents (resume and personal info)
    Returns document information including filename, size, and processing status
    """
    try:
        # Get document service
        doc_service = get_document_service()
        
        # Get documents status for the authenticated user
        documents_status = doc_service.get_documents_status(user.id)
        
        logger.info(f"üìã Retrieved documents status for user {user.id}: {documents_status}")
        
        return DocumentStatusResponse(
            status="success",
            documents=documents_status,
            user_id=user.id,
            message="Documents status retrieved successfully"
        )
        
    except Exception as e:
        logger.error(f"‚ùå Error getting documents status for user {user.id}: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error retrieving documents status: {str(e)}"
        )

# ============================================================================
# DEMO ENDPOINT (No Authentication Required)
# ============================================================================

@app.post("/api/demo/generate-field-answer", response_model=FieldAnswerResponse)
async def demo_generate_field_answer(field_request: FieldAnswerRequest) -> FieldAnswerResponse:
    """
    üéØ DEMO: Generate field answer using Redis Vector Store (no authentication)
    
    This endpoint is for testing/demo purposes only.
    For production use, users should register and use the main endpoint.
    """
    try:
        logger.info(f"üéØ DEMO: Generating answer for field: '{field_request.label}' on {field_request.url}")
        logger.info(f"üë§ Using demo user: default")
        
        # Get the RAG service (same as main endpoint)
        from app.services.rag_service import RAGService
        rag_service = RAGService()
        
        # Use the user_id from the request
        user_id = field_request.user_id or "6fe5bceb-8c76-4db6-a0ec-79c65c6a9346"
        
        # Generate answer using RAG service
        result = await asyncio.to_thread(rag_service.generate_field_answer, field_request.label, user_id)
        
        # Extract the answer from the RAG result
        answer = result.get("answer", "Unable to generate answer")
        data_source = result.get("data_source", "unknown")
        reasoning = result.get("reasoning", "No reasoning provided")
        confidence = result.get("confidence", 0)
        similarity_scores = result.get("similarity_scores", [])
        
        # Get performance metrics
        processing_time = time.time() - time.time()  # Will be set properly below
        performance_metrics = {
            "processing_time_seconds": processing_time,
            "optimization_enabled": True,
            "cache_hits": 0,
            "early_exit": False,
            "tier_exit": 1 if data_source.startswith("high_confidence") else 3,
            "tiers_used": 1 if data_source.startswith("high_confidence") else 3
        }
        
        logger.info(f"‚úÖ DEMO RAG Generated answer: '{answer}' (source: {data_source}, confidence: {confidence}%)")
        if similarity_scores:
            logger.info(f"üîç Similarity scores: {[f'{s:.3f}' for s in similarity_scores[:3]]}")
        
        return FieldAnswerResponse(
            answer=answer,
            data_source=data_source,
            reasoning=reasoning,
            status="success",
            performance_metrics=performance_metrics
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå DEMO Error generating field answer: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

# ============================================================================
# DEMO DOCUMENT UPLOAD ENDPOINTS (No Authentication Required)
# ============================================================================

# Additional Pydantic models for document operations
class DocumentUploadResponse(BaseModel):
    status: str
    message: str
    document_id: int
    filename: str
    file_size: int
    content_type: str
    processing_time: float
    replaced_previous: bool  # Indicates if a previous document was replaced

@app.post("/api/demo/resume/upload", response_model=DocumentUploadResponse)
async def demo_upload_resume(file: UploadFile = File(...)):
    """
    üìÑ DEMO: Upload resume document (no authentication, user_id='default')
    Automatically embeds the document after upload.
    """
    start_time = time.time()
    try:
        file_content = await file.read()
        document_id = document_service.save_resume_document(
            filename=file.filename,
            file_content=file_content,
            content_type=file.content_type,
            user_id="default"
        )
        # Extract text for embedding
        try:
            text = await extract_text_from_file(file_content, file.content_type)
            embedding_service = get_embedding_service()
            embedding_service.process_document(
                document_id=f"resume_{document_id}",
                user_id="default",
                content=text,
                reprocess=True
            )
            logger.info(f"‚úÖ Embedded resume document {document_id} for user 'default'")
        except Exception as embed_err:
            logger.error(f"‚ùå Embedding failed for resume {document_id}: {embed_err}")
        processing_time = time.time() - start_time
        return {
            "status": "success",
            "message": "Demo resume uploaded and embedded successfully",
            "document_id": document_id,
            "filename": file.filename,
            "file_size": len(file_content),
            "content_type": file.content_type,
            "processing_time": round(processing_time, 3),
            "replaced_previous": True
        }
    except Exception as e:
        logger.error(f"‚ùå Demo resume upload failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Demo resume upload failed: {str(e)}")

@app.post("/api/demo/personal-info/upload", response_model=DocumentUploadResponse)
async def demo_upload_personal_info(content: str = Form(...)):
    """
    üìù DEMO: Upload personal info document (no authentication, user_id='default')
    Automatically embeds the document after upload.
    """
    start_time = time.time()
    try:
        file_content = content.encode("utf-8")
        filename = "personal_info.txt"
        content_type = "text/plain"
        document_id = document_service.save_personal_info_document(
            filename=filename,
            file_content=file_content,
            content_type=content_type,
            user_id="default"
        )
        # Embed personal info
        try:
            embedding_service = get_embedding_service()
            embedding_service.process_document(
                document_id=f"personal_info_{document_id}",
                user_id="default",
                content=content,
                reprocess=True
            )
            logger.info(f"‚úÖ Embedded personal info document {document_id} for user 'default'")
        except Exception as embed_err:
            logger.error(f"‚ùå Embedding failed for personal info {document_id}: {embed_err}")
        processing_time = time.time() - start_time
        return {
            "status": "success",
            "message": "Demo personal info uploaded and embedded successfully",
            "document_id": document_id,
            "filename": filename,
            "file_size": len(file_content),
            "content_type": content_type,
            "processing_time": round(processing_time, 3),
            "replaced_previous": True
        }
    except Exception as e:
        logger.error(f"‚ùå Demo personal info upload failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Demo personal info upload failed: {str(e)}")

# ============================================================================
# OPTIMIZED VECTOR DATABASE ENDPOINTS
# ============================================================================

@app.post("/api/v1/resume/reembed")
async def reembed_resume(
    user: User = Depends(get_session_user)
):
    """
    üîÑ Re-process resume document into vector embeddings and store in Redis
    
    This will:
    1. Load user's resume document from database
    2. Extract text content
    3. Generate chunks
    4. Create OpenAI embeddings
    5. Store in Redis vector store
    """
    try:
        # Get document service and embedding service
        document_service = get_document_service()
        embedding_service = EmbeddingService()
        
        # Get document
        document = document_service.get_user_resume(user.id if user else None)
        if not document:
            raise HTTPException(
                status_code=404,
                detail="No resume document found"
            )
        
        # Update status to processing
        document_service.update_resume_status(document.id, "processing")
        
        try:
            # Extract text from file content
            text = await extract_text_from_file(document.file_content, document.content_type)
            
            # Process document with Redis storage
            embedding_service.process_document(
                document_id=f"resume_{document.id}",
                user_id=user.id,
                content=text,
                reprocess=True
            )
            
            # Update status to completed
            document_service.update_resume_status(document.id, "completed")
            
            return {
                "status": "success",
                "message": "Resume document processed and stored in Redis successfully",
                "document_id": document.id,
                "user_id": user.id,
                "storage": "redis"
            }
            
        except Exception as e:
            # Update status to failed
            document_service.update_resume_status(document.id, "failed")
            raise e
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error processing resume: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Error processing resume: {str(e)}"
        )



@app.post("/api/v1/personal-info/reembed", response_model=ReembedResponse)
async def reembed_personal_info_from_database(
    user: User = Depends(get_session_user)
):
    """‚ö° OPTIMIZED: Re-embed personal info from database using Redis vector store"""
    start_time = datetime.now()
    
    try:
        # Get document service and embedding service with smaller chunks for personal info
        document_service = get_document_service()
        embedding_service = EmbeddingService(
            chunk_size=200,  # Much smaller chunks for personal info (was 800)
            chunk_overlap=30  # Smaller overlap (was 100)
        )
        
        logger.info(f"üîÑ Re-embedding personal info from database for user: {user.id} with smaller chunks")
        
        # Get personal info document (‚úÖ FIXED: correct method name)
        personal_info_doc = document_service.get_personal_info_document(user.id)
        if not personal_info_doc:
            raise HTTPException(status_code=404, detail="No personal info document found for this user")
        
        # Update status to processing
        document_service.update_personal_info_status(personal_info_doc.id, "processing")
        
        try:
            # Process document with Redis storage
            content = personal_info_doc.file_content.decode() if isinstance(personal_info_doc.file_content, bytes) else personal_info_doc.file_content
            
            embedding_service.process_document(
                document_id=f"personal_info_{personal_info_doc.id}",
                user_id=user.id,
                content=content,
                reprocess=True
            )
            
            # Update status to completed
            document_service.update_personal_info_status(personal_info_doc.id, "completed")
            
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()
            
            return ReembedResponse(
                status="success",
                message=f"Personal info re-embedded and stored in Redis successfully in {processing_time:.2f}s",
                processing_time=processing_time,
                database_info={
                    "user_id": user.id,
                    "document_id": personal_info_doc.id,
                    "storage": "redis",
                    "optimization_enabled": True
                }
            )
            
        except Exception as e:
            # Update status to failed
            document_service.update_personal_info_status(personal_info_doc.id, "failed")
            raise e
    
    except HTTPException:
        raise
    except Exception as e:
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        logger.error(f"‚ùå Personal info re-embedding failed: {e}")
        raise HTTPException(status_code=500, detail=f"Re-embedding failed: {str(e)}")

@app.get("/api/v1/documents/status/all")
async def get_documents_status_legacy(user_id: str = Query(None, description="User ID for multi-user support")):
    """‚ö° LEGACY: Get documents status using cached service (for backward compatibility)"""
    try:
        document_service = get_document_service()
        
        # Get document status from database
        status_data = document_service.get_documents_status(user_id)
        
        return {
            "status": "success",
            "user_id": user_id,
            "documents": status_data,
            "optimization_enabled": True,
            "timestamp": datetime.now().isoformat()
        }
    
    except Exception as e:
        logger.error(f"‚ùå Status check failed: {e}")
        raise HTTPException(status_code=500, detail=f"Status check failed: {str(e)}")

# ============================================================================
# DOCUMENT UPLOAD & CRUD ENDPOINTS
# ============================================================================

class DocumentInfoResponse(BaseModel):
    id: int
    filename: str
    file_size: int
    content_type: str
    processing_status: str
    user_id: Optional[str] = None

# ============================================================================
# RESUME DOCUMENT ENDPOINTS (ONE PER USER)
# ============================================================================

@app.post("/api/v1/resume/upload", response_model=DocumentUploadResponse)
async def upload_resume(
    file: UploadFile = File(...),
    user: User = Depends(get_session_user)
):
    """
    üìÑ Upload resume document to database (One per user - replaces existing)
    Automatically processes document into vector embeddings (Pinecone/Redis)
    
    Supports:
    - PDF (.pdf)
    - Word (.doc, .docx)
    - Text (.txt)
    """
    start_time = time.time()
    
    try:
        # Read file content
        file_content = await file.read()
        
        # Save document to database
        service_start = time.time()
        document_id = document_service.save_resume_document(
            filename=file.filename,
            file_content=file_content,
            content_type=file.content_type,
            user_id=user.id if user else None
        )
        service_time = time.time() - service_start
        
        # Extract text and process into vector embeddings
        embed_start = time.time()
        try:
            text = await extract_text_from_file(file_content, file.content_type)
            embedding_service = get_embedding_service()
            embedding_service.process_document(
                document_id=f"resume_{document_id}",
                user_id=user.id,
                content=text,
                reprocess=True
            )
            logger.info(f"‚úÖ Resume document {document_id} processed into vector store for user {user.id}")
        except Exception as embed_err:
            logger.error(f"‚ùå Vector embedding failed for resume {document_id}: {embed_err}")
            # Continue without failing the upload
        
        embed_time = time.time() - embed_start
        processing_time = time.time() - start_time
        
        return {
            "status": "success",
            "message": "Resume uploaded and processed successfully",
            "document_id": document_id,
            "filename": file.filename,
            "file_size": len(file_content),
            "content_type": file.content_type,
            "processing_time": round(processing_time, 3),
            "replaced_previous": True  # Since we always replace previous resume
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error uploading resume: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Error uploading resume: {str(e)}"
        )

@app.get("/api/v1/resume")
async def get_user_resume(
    user: User = Depends(get_session_user)
):
    """üìÑ Get user's resume document info"""
    try:
        document_service = get_document_service()
        document = document_service.get_user_resume(user.id)
        
        if not document:
            raise HTTPException(status_code=404, detail="No resume found for this user")
        
        return DocumentInfoResponse(
            id=document.id,
            filename=document.filename,
            file_size=len(document.file_content),
            content_type=document.content_type,
            processing_status=document.processing_status,
            user_id=document.user_id
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Failed to get resume document: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get document: {str(e)}")

@app.delete("/api/v1/resume")
async def delete_user_resume(
    user: User = Depends(get_session_user)
):
    """üóëÔ∏è Delete user's resume document"""
    try:
        document_service = get_document_service()
        with document_service.get_session() as session:
            result = session.query(ResumeDocument).filter(
                ResumeDocument.user_id == user.id
            ).delete()
            
            if result == 0:
                raise HTTPException(status_code=404, detail="No resume found for this user")
            
            session.commit()
            
            return {"status": "success", "message": "Resume deleted successfully"}
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Failed to delete resume: {e}")
        raise HTTPException(status_code=500, detail=f"Delete failed: {str(e)}")

@app.get("/api/v1/documents/status")
async def get_user_documents_status(
    user: User = Depends(get_session_user)
):
    """üìä Get status of user's documents"""
    try:
        document_service = get_document_service()
        status = document_service.get_documents_status(user.id)
        
        return {
            "status": "success",
            "data": status
        }
        
    except Exception as e:
        logger.error(f"‚ùå Failed to get documents status: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# PERSONAL INFO DOCUMENT ENDPOINTS (ONE PER USER)
# ============================================================================

@app.post("/api/v1/personal-info/upload", response_model=DocumentUploadResponse)
async def upload_personal_info(
    file: UploadFile = File(...),
    user: User = Depends(get_session_user)
):
    """
    üìÑ Upload personal info document to database (One per user - replaces existing)
    Automatically processes document into vector embeddings (Pinecone/Redis)
    
    Supports:
    - PDF (.pdf)
    - Word (.doc, .docx)
    - Text (.txt)
    """
    start_time = time.time()
    
    try:
        # Read file content
        file_content = await file.read()
        
        # Save document to database
        service_start = time.time()
        document_id = document_service.save_personal_info_document(
            filename=file.filename,
            file_content=file_content,
            content_type=file.content_type,
            user_id=user.id if user else None
        )
        service_time = time.time() - service_start
        
        # Extract text and process into vector embeddings
        embed_start = time.time()
        try:
            text = await extract_text_from_file(file_content, file.content_type)
            embedding_service = get_embedding_service()
            embedding_service.process_document(
                document_id=f"personal_info_{document_id}",
                user_id=user.id,
                content=text,
                reprocess=True
            )
            logger.info(f"‚úÖ Personal info document {document_id} processed into vector store for user {user.id}")
        except Exception as embed_err:
            logger.error(f"‚ùå Vector embedding failed for personal info {document_id}: {embed_err}")
            # Continue without failing the upload
        
        embed_time = time.time() - embed_start
        processing_time = time.time() - start_time
        
        return {
            "status": "success",
            "message": "Personal info document uploaded and processed successfully",
            "document_id": document_id,
            "filename": file.filename,
            "file_size": len(file_content),
            "content_type": file.content_type,
            "processing_time": round(processing_time, 3),
            "replaced_previous": True  # Since we always replace previous document
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error uploading personal info: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Error uploading personal info: {str(e)}"
        )

@app.get("/api/v1/personal-info", response_model=DocumentInfoResponse)
async def get_personal_info(user: User = Depends(get_session_user)):
    """Get personal info document info"""
    try:
        document = document_service.get_personal_info_document(
            user_id=user.id if user else None
        )
        
        if not document:
            raise HTTPException(
                status_code=404,
                detail="No personal info document found"
            )
        
        return DocumentInfoResponse(
            id=document.id,
            filename=document.filename,
            file_size=len(document.file_content),
            content_type=document.content_type,
            processing_status=document.processing_status,
            user_id=document.user_id
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error retrieving personal info: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Error retrieving personal info: {str(e)}"
        )

@app.get("/api/v1/resume/download")
async def download_user_resume(
    user: User = Depends(get_session_user)
):
    """‚¨áÔ∏è Download user's resume document"""
    try:
        document_service = get_document_service()
        document = document_service.get_user_resume(user.id)
        
        if not document:
            raise HTTPException(status_code=404, detail="No resume found for this user")
        
        return StreamingResponse(
            io.BytesIO(document.file_content),
            media_type=document.content_type,
            headers={"Content-Disposition": f"attachment; filename={document.filename}"}
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Failed to download resume: {e}")
        raise HTTPException(status_code=500, detail=f"Download failed: {str(e)}")

@app.get("/api/v1/personal-info/download")
async def download_user_personal_info(
    user: User = Depends(get_session_user)
):
    """‚¨áÔ∏è Download user's personal info document"""
    try:
        document_service = get_document_service()
        document = document_service.get_personal_info_document(user.id)
        
        if not document:
            raise HTTPException(status_code=404, detail="No personal info found for this user")
        
        return StreamingResponse(
            io.BytesIO(document.file_content),
            media_type=document.content_type,
            headers={"Content-Disposition": f"attachment; filename={document.filename}"}
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Failed to download personal info: {e}")
        raise HTTPException(status_code=500, detail=f"Download failed: {str(e)}")

@app.delete("/api/v1/personal-info")
async def delete_user_personal_info(
    user: User = Depends(get_session_user)
):
    """üóëÔ∏è Delete user's personal info document"""
    try:
        document_service = get_document_service()
        with document_service.get_session() as session:
            result = session.query(PersonalInfoDocument).filter(
                PersonalInfoDocument.user_id == user.id,
                PersonalInfoDocument.is_active == True
            ).update({"is_active": False})
            
            if result == 0:
                raise HTTPException(status_code=404, detail="No personal info found for this user")
            
            session.commit()
            
            return {"status": "success", "message": "Personal info deleted successfully"}
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Failed to delete personal info: {e}")
        raise HTTPException(status_code=500, detail=f"Delete failed: {str(e)}")

# ============================================================================
# VECTOR EMBEDDING MANAGEMENT ENDPOINTS
# ============================================================================

@app.post("/api/v1/resume/reembed")
async def reembed_resume(
    user: User = Depends(get_session_user)
):
    """
    üîÑ Re-process existing resume document into vector embeddings
    Useful for updating embeddings with new models or after index changes
    """
    try:
        document_service = get_document_service()
        document = document_service.get_user_resume(user.id)
        
        if not document:
            raise HTTPException(status_code=404, detail="No resume found for this user")
        
        # Extract text and process into vector embeddings
        try:
            text = await extract_text_from_file(document.file_content, document.content_type)
            embedding_service = get_embedding_service()
            embedding_service.process_document(
                document_id=f"resume_{document.id}",
                user_id=user.id,
                content=text,
                reprocess=True
            )
            logger.info(f"‚úÖ Resume document {document.id} re-embedded for user {user.id}")
            
            return {
                "status": "success",
                "message": "Resume re-embedded successfully",
                "document_id": document.id,
                "filename": document.filename
            }
        except Exception as embed_err:
            logger.error(f"‚ùå Re-embedding failed for resume {document.id}: {embed_err}")
            raise HTTPException(
                status_code=500,
                detail=f"Re-embedding failed: {str(embed_err)}"
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error re-embedding resume: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error re-embedding resume: {str(e)}")

@app.post("/api/v1/personal-info/reembed")
async def reembed_personal_info(
    user: User = Depends(get_session_user)
):
    """
    üîÑ Re-process existing personal info document into vector embeddings
    Useful for updating embeddings with new models or after index changes
    """
    try:
        document_service = get_document_service()
        document = document_service.get_active_personal_info_document(user.id)
        
        if not document:
            raise HTTPException(status_code=404, detail="No personal info found for this user")
        
        # Extract text and process into vector embeddings
        try:
            text = await extract_text_from_file(document.file_content, document.content_type)
            embedding_service = get_embedding_service()
            embedding_service.process_document(
                document_id=f"personal_info_{document.id}",
                user_id=user.id,
                content=text,
                reprocess=True
            )
            logger.info(f"‚úÖ Personal info document {document.id} re-embedded for user {user.id}")
            
            return {
                "status": "success",
                "message": "Personal info re-embedded successfully",
                "document_id": document.id,
                "filename": document.filename
            }
        except Exception as embed_err:
            logger.error(f"‚ùå Re-embedding failed for personal info {document.id}: {embed_err}")
            raise HTTPException(
                status_code=500,
                detail=f"Re-embedding failed: {str(embed_err)}"
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error re-embedding personal info: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error re-embedding personal info: {str(e)}")

@app.get("/api/v1/vector-store/stats")
async def get_vector_store_stats(
    user: User = Depends(get_session_user)
):
    """
    üìä Get vector store statistics for user
    Shows document counts and vector store type (Pinecone/Redis)
    """
    try:
        embedding_service = get_embedding_service()
        stats = embedding_service.get_document_stats(user.id)
        
        return {
            "status": "success",
            "user_id": user.id,
            "vector_store_type": "Pinecone" if hasattr(embedding_service.vector_store, 'index') else "Redis",
            "stats": stats
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error getting vector store stats: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error getting stats: {str(e)}")

@app.delete("/api/v1/vector-store/clear")
async def clear_user_vectors(
    user: User = Depends(get_session_user)
):
    """
    üóëÔ∏è Clear all vector embeddings for user
    Removes all stored vectors but keeps documents in database
    """
    try:
        embedding_service = get_embedding_service()
        
        # Clear resume vectors
        try:
            embedding_service.vector_store.delete_all_documents(user.id, "resume")
            logger.info(f"‚úÖ Cleared resume vectors for user {user.id}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error clearing resume vectors: {e}")
        
        # Clear personal info vectors
        try:
            embedding_service.vector_store.delete_all_documents(user.id, "personal_info")
            logger.info(f"‚úÖ Cleared personal info vectors for user {user.id}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error clearing personal info vectors: {e}")
        
        return {
            "status": "success",
            "message": "All vector embeddings cleared successfully",
            "user_id": user.id
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error clearing vectors: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error clearing vectors: {str(e)}")

@app.get("/api/v1/resume/search")
async def search_resume_vectors(
    query: str = Query(..., description="Search query"),
    top_k: int = Query(5, description="Number of results to return"),
    min_score: float = Query(0.1, description="Minimum similarity score"),
    user: User = Depends(get_session_user)
):
    """
    üîç Search resume vectors using semantic similarity
    Returns relevant chunks from user's resume documents
    """
    try:
        embedding_service = get_embedding_service()
        
        results = embedding_service.search_similar_by_document_type(
            query=query,
            user_id=user.id,
            document_type="resume",
            top_k=top_k,
            min_score=min_score
        )
        
        logger.info(f"‚úÖ Resume search completed - Found {len(results)} results for user {user.id}")
        
        return results
        
    except Exception as e:
        logger.error(f"‚ùå Resume search failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Search failed: {str(e)}")

# ============================================================================
# FULL JWT AUTHENTICATION ENDPOINTS (Optional)
# ============================================================================

@app.get("/api/auth/validate")
async def validate_session(user: User = Depends(get_session_user)):
    """
    üîç Validate current session
    Returns user info if session is valid
    """
    return {
        "valid": True,
        "user_id": user.id,
        "email": user.email
    }

# ============================================================================
# HEALTH CHECK ENDPOINTS
# ============================================================================

@app.get("/")
async def root():
    """Root endpoint with optimization info"""
    return {
        "message": "Smart Form Fill API - OPTIMIZED VERSION",
        "version": "4.1.0-optimized",
        "status": "operational",
        "performance_enhancements": [
            "Singleton pattern with cached services",
            "Connection pooling",
            "Pre-warmed services",
            "Optimized vector operations",
            "Performance metrics tracking"
        ],
        "docs": "/docs",
        "health": "/health"
    }

@app.get("/health")
async def health_check():
    """Simple health check for Railway deployment"""
    try:
        return {
            "status": "healthy",
            "version": "4.1.0-optimized",
            "timestamp": datetime.now().isoformat(),
            "services": {
                "api": "healthy",
                "database": "ready",
                "redis": "ready",
                "openai": "ready"
            },
            "optimization_status": "enabled"
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# Analysis status endpoint removed

# ============================================================================
# REDIS WORKFLOW TEST ENDPOINT
# ============================================================================

class RedisWorkflowTestResponse(BaseModel):
    status: str
    workflow_steps: Dict[str, Any]
    sample_search_results: Dict[str, int]
    processing_time: float
    error: Optional[str] = None

@app.post("/api/test/redis-workflow", response_model=RedisWorkflowTestResponse)
async def test_redis_workflow(user: User = Depends(get_session_user)):
    """
    Test the complete Redis vector workflow:
    1. Get resume from DB
    2. Re-embed (generate embeddings) 
    3. Store vectors in Redis
    4. LLM searches Redis for form filling
    """
    start_time = time.time()
    
    try:
        from app.services.vector_store import RedisVectorStore
        import numpy as np
        import openai
        
        # Initialize Redis vector store
        vector_store = RedisVectorStore(
            redis_url=REDIS_URL,
            index_name=f"workflow_test_{user.id}",
            vector_dim=1536
        )
        
        # STEP 1: Get resume from DB
        logger.info(f"üìÑ Step 1: Getting resume from DB for user {user.id}")
        document_service = get_document_service()
        resume_doc = document_service.get_user_resume(user.id)
        
        if not resume_doc:
            # Use sample resume for testing
            resume_text = """
            John Doe - Software Engineer
            
            Experience:
            ‚Ä¢ 5 years Python development at Tech Corp
            ‚Ä¢ Led team of 4 developers on AI projects
            ‚Ä¢ Built FastAPI microservices with Redis
            ‚Ä¢ Implemented machine learning pipelines
            
            Skills:
            ‚Ä¢ Languages: Python, JavaScript, TypeScript
            ‚Ä¢ Frameworks: FastAPI, React, Node.js
            ‚Ä¢ Databases: PostgreSQL, Redis, MongoDB
            ‚Ä¢ Cloud: AWS, Docker, Kubernetes
            ‚Ä¢ AI/ML: OpenAI API, LangChain, scikit-learn
            
            Education:
            ‚Ä¢ BS Computer Science, Stanford University
            ‚Ä¢ Machine Learning Specialization, Coursera
            """
        else:
            resume_text = resume_doc.extracted_text or "No text extracted"
        
        # STEP 2: Re-embed (generate embeddings)
        logger.info("üî¢ Step 2: Re-embedding resume text...")
        
        # Simple text chunking
        chunks = []
        chunk_size = 800
        chunk_overlap = 100
        start = 0
        while start < len(resume_text):
            end = start + chunk_size
            chunk = resume_text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            start = end - chunk_overlap
        
        # Get embeddings using OpenAI
        try:
            response = openai.embeddings.create(
                model="text-embedding-3-small",
                input=chunks
            )
            embeddings = [np.array(e.embedding) for e in response.data]
        except Exception as e:
            logger.warning(f"OpenAI embedding failed, using random embeddings for test: {e}")
            embeddings = [np.random.rand(1536).astype(np.float32) for _ in chunks]
        
        # Prepare chunk data
        chunk_data = []
        for i, (text, embedding) in enumerate(zip(chunks, embeddings)):
            chunk_data.append({
                "chunk_id": f"chunk_{i}",
                "text": text,
                "embedding": embedding
            })
        
        # STEP 3: Store vectors in Redis
        logger.info("üíæ Step 3: Storing vectors in Redis...")
        document_id = f"resume_{user.id}_test"
        vector_store.store_embeddings(document_id, str(user.id), chunk_data)
        
        # STEP 4: LLM searches Redis for form filling
        logger.info("üîç Step 4: Testing form field searches...")
        
        form_queries = [
            "What programming languages do you know?",
            "What is your work experience?", 
            "What is your education background?",
            "What are your technical skills?"
        ]
        
        search_results = {}
        for query in form_queries:
            # Get query embedding
            try:
                query_response = openai.embeddings.create(
                    model="text-embedding-3-small",
                    input=[query]
                )
                query_embedding = np.array(query_response.data[0].embedding)
            except Exception:
                query_embedding = np.random.rand(1536).astype(np.float32)
            
            # Search Redis
            results = vector_store.search_similar(
                query_embedding=query_embedding,
                user_id=str(user.id),
                top_k=2,
                min_score=0.1
            )
            
            search_results[query] = len(results)
        
        # STEP 5: Cleanup test data
        logger.info("üßπ Step 5: Cleaning up test data...")
        vector_store.delete_document(document_id, str(user.id))
        
        processing_time = time.time() - start_time
        
        return RedisWorkflowTestResponse(
            status="success",
            workflow_steps={
                "1_resume_chunks": len(chunks),
                "2_embeddings_generated": len(embeddings),
                "3_vectors_stored": len(chunk_data),
                "4_form_queries_tested": len(form_queries),
                "5_cleanup_completed": True
            },
            sample_search_results=search_results,
            processing_time=processing_time
        )
        
    except Exception as e:
        processing_time = time.time() - start_time
        logger.error(f"‚ùå Redis workflow test failed: {e}")
        
        return RedisWorkflowTestResponse(
            status="failed",
            workflow_steps={},
            sample_search_results={},
            processing_time=processing_time,
            error=str(e)
        )

@app.post("/api/logout")
async def logout_user(session_data: dict, db: Session = Depends(get_db)):
    """
    üîì Logout: Deactivate user session
    """
    try:
        session_id = session_data.get("session_id")
        if not session_id:
            raise HTTPException(status_code=400, detail="Session ID is required")
            
        # Find and deactivate session
        session = db.query(UserSession).filter(
            UserSession.session_id == session_id,
            UserSession.is_active == True
        ).first()
        
        if not session:
            raise HTTPException(status_code=404, detail="Session not found")
            
        session.is_active = False
        db.commit()
        
        logger.info(f"‚úÖ User logged out (Session: {session_id})")
        
        return {"status": "success", "message": "Logged out successfully"}
        
    except Exception as e:
        logger.error(f"‚ùå Logout failed: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

class UpdateSessionResponse(BaseModel):
    """
    Response for session update/creation
    """
    status: str
    session_id: str
    user_id: str
    message: str

@app.post("/api/session/check-and-update/{user_id}", response_model=UpdateSessionResponse)
async def check_and_update_session(
    user_id: str,
    db: Session = Depends(get_db)
):
    """
    Check if user has any existing sessions and update/create as needed
    Ensures only one active session per user
    """
    try:
        # Validate user exists and is active
        user = db.query(User).filter(
            User.id == user_id,
            User.is_active == True
        ).first()
        
        if not user:
            raise HTTPException(status_code=404, detail="User not found or inactive")
        
        # Deactivate all existing sessions for this user
        db.query(UserSession).filter(
            UserSession.user_id == user_id,
            UserSession.is_active == True
        ).update({
            "is_active": False,
            "last_used_at": datetime.utcnow()
        })
        db.commit()
        
        # Find most recent session
        existing_session = db.query(UserSession).filter(
            UserSession.user_id == user_id
        ).order_by(UserSession.last_used_at.desc()).first()
        
        if existing_session:
            # Reactivate most recent session
            existing_session.last_used_at = datetime.utcnow()
            existing_session.is_active = True
            db.commit()
            
            logger.info(f"‚úÖ Session reactivated for user: {user.email} (Session: {existing_session.session_id})")
            
            return UpdateSessionResponse(
                status="updated",
                session_id=existing_session.session_id,
                user_id=user_id,
                message="Existing session reactivated"
            )
        else:
            # Create new session
            new_session = UserSession(
                user_id=user_id,
                device_info="Optional Device Info",
                is_active=True
            )
            db.add(new_session)
            db.commit()
            db.refresh(new_session)
            
            logger.info(f"‚úÖ New session created for user: {user.email} (Session: {new_session.session_id})")
            
            return UpdateSessionResponse(
                status="created",
                session_id=new_session.session_id,
                user_id=user_id,
                message="New session created"
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Session check/update failed: {e}")
        raise HTTPException(status_code=500, detail="Session check/update failed")

@app.post("/api/test/redis-field-answer")
async def test_redis_field_answer(field_request: FieldAnswerRequest):
    """üß™ Test Redis vector search directly for field answers"""
    try:
        from app.services.vector_store import VectorStore
        
        # Initialize Redis vector store
        vector_store = VectorStore()
        
        # Search for relevant information
        search_results = vector_store.search_similar_by_document_type(
            query=field_request.label,
            user_id="1eeb606f-f098-4a04-a5c7-5ff373e61903",  # Your user ID
            document_type="resume",
            top_k=3
        )
        
        # Extract answer from search results
        if search_results:
            answer = search_results[0].get('text', 'No answer found')[:100]  # First 100 chars
        else:
            answer = "No relevant information found"
        
        return FieldAnswerResponse(
            answer=answer,
            data_source="redis_vector_store",
            reasoning="Direct Redis search test",
            status="success",
            performance_metrics={"search_results_count": len(search_results)}
        )
        
    except Exception as e:
        return FieldAnswerResponse(
            answer="Error occurred",
            data_source="error",
            reasoning=str(e),
            status="error"
        )

# ============================================================================
# TEXT TRANSLATION ENDPOINT (For Browser Extension Text Highlighting)
# ============================================================================

@app.post("/api/translate", response_model=TranslationResponse)
async def translate_text(translation_request: TranslationRequest):
    """
    üåê Translate highlighted text from any website
    
    Supports English ‚Üí Russian translation for browser extension
    Uses OpenAI GPT for high-quality translation
    """
    try:
        from openai import OpenAI
        
        # Initialize OpenAI client
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # Create translation prompt
        translation_prompt = f"""
        Please translate the following text from {translation_request.source_language} to {translation_request.target_language}.
        Provide only the translation, no explanations or additional text.
        
        Text to translate: "{translation_request.text}"
        
        Translation:
        """
        
        # Get translation from OpenAI
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a professional translator. Provide accurate, natural translations without any additional text or explanations."},
                {"role": "user", "content": translation_prompt}
            ],
            max_tokens=500,
            temperature=0.3  # Lower temperature for more consistent translations
        )
        
        translated_text = response.choices[0].message.content.strip()
        
        logger.info(f"‚úÖ Translated '{translation_request.text[:50]}...' from {translation_request.source_language} to {translation_request.target_language}")
        
        return TranslationResponse(
            original_text=translation_request.text,
            translated_text=translated_text,
            source_language=translation_request.source_language,
            target_language=translation_request.target_language,
            confidence=0.95,  # OpenAI typically provides high-quality translations
            status="success"
        )
        
    except Exception as e:
        logger.error(f"‚ùå Translation failed: {str(e)}")
        return TranslationResponse(
            original_text=translation_request.text,
            translated_text=f"Translation failed: {str(e)}",
            source_language=translation_request.source_language,
            target_language=translation_request.target_language,
            confidence=0.0,
            status="error"
        )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=PORT, reload=False)  # Use PORT env var for Railway deployment

 
