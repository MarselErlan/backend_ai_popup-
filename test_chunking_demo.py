#!/usr/bin/env python3
"""
Comprehensive test to demonstrate improved chunking for personal info
Shows the difference between old (large) and new (small) chunks
"""

import sys
import os
from pathlib import Path

# Add the app directory to the Python path
sys.path.append(str(Path(__file__).parent))

from app.services.embedding_service import EmbeddingService
from loguru import logger

def test_old_vs_new_chunking():
    """Test to show the difference between old (800 characters) and new (200 characters) chunking"""
    
    # Your exact personal info example
    personal_info_text = """Name: Eric Abram
Phone: 312-805-9851
Email: ericabram33@gmail.com
Location: San Francisco, CA
LinkedIn: https://linkedin.com/in/eric-abram
GitHub: https://github.com/ericabram
Portfolio: https://ericabram.dev

About Me:
I'm a Full-Stack Software Test Automation Engineer (SDET) with 8+ years of experience in backend development and quality engineering. My career began in manual testing and evolved through backend development using Python, Django, and FastAPI, before returning to test automation to build intelligent, scalable testing pipelines.

I specialize in developing robust frameworks for UI, API, and database testing using tools like Selenium, Playwright, RestAssured, Jenkins, and Kubernetes. I've worked on high-impact systems across healthcare, banking, and global e-commerce platforms, ensuring quality at scale.

Core Skills:
â€¢ Test Automation: Selenium WebDriver, Playwright, Cypress, TestNG, JUnit
â€¢ API Testing: RestAssured, Postman, Newman, API security testing
â€¢ Backend Development: Python, Java, Node.js, Django, FastAPI, Spring Boot
â€¢ Database Testing: SQL, NoSQL, data validation, migration testing
â€¢ CI/CD: Jenkins, GitHub Actions, Docker, Kubernetes deployment pipelines
â€¢ Performance Testing: JMeter, LoadRunner, stress testing methodologies
â€¢ Cloud Platforms: AWS, GCP, containerization, microservices testing

Professional Experience:

Senior SDET at TechCorp (2020-Present)
â€¢ Built comprehensive test automation framework reducing manual testing by 85%
â€¢ Implemented API testing suite covering 200+ endpoints with 95% coverage
â€¢ Designed database validation framework for financial transactions
â€¢ Led migration from legacy testing tools to modern automation stack
â€¢ Mentored junior engineers in test automation best practices

Backend Developer at StartupXYZ (2018-2020)
â€¢ Developed REST APIs using Django and FastAPI serving 100K+ daily requests
â€¢ Implemented database optimization reducing query response time by 60%
â€¢ Built microservices architecture with Docker and Kubernetes
â€¢ Created automated deployment pipelines with Jenkins and AWS
â€¢ Collaborated with frontend team on API design and integration

QA Engineer at Enterprise Solutions (2016-2018)
â€¢ Performed manual and automated testing for enterprise web applications
â€¢ Created test cases and documentation for complex business workflows
â€¢ Implemented regression testing suite reducing release cycle time
â€¢ Worked closely with development team on bug resolution and quality metrics"""

    print("ðŸ” CHUNKING COMPARISON TEST")
    print("=" * 80)
    
    # OLD CHUNKING (800 characters - what you had before)
    print("\nâŒ OLD CHUNKING (800 characters):")
    print("-" * 50)
    
    old_embedding_service = EmbeddingService(chunk_size=800, chunk_overlap=100)
    old_chunks = old_embedding_service._chunk_text(personal_info_text)
    
    for i, chunk in enumerate(old_chunks, 1):
        print(f"\nðŸ“„ OLD CHUNK {i} ({len(chunk)} chars):")
        print(f"'{chunk[:200]}{'...' if len(chunk) > 200 else ''}'")
    
    print(f"\nðŸ“Š OLD CHUNKING SUMMARY:")
    print(f"   â€¢ Total chunks: {len(old_chunks)}")
    print(f"   â€¢ Average chunk size: {sum(len(c) for c in old_chunks) // len(old_chunks)} chars")
    print(f"   â€¢ Largest chunk: {max(len(c) for c in old_chunks)} chars")
    
    # NEW CHUNKING (200 characters - what you have now)
    print("\nâœ… NEW CHUNKING (200 characters):")
    print("-" * 50)
    
    new_embedding_service = EmbeddingService(chunk_size=200, chunk_overlap=30)
    new_chunks = new_embedding_service._chunk_text(personal_info_text)
    
    for i, chunk in enumerate(new_chunks, 1):
        print(f"\nðŸ“„ NEW CHUNK {i} ({len(chunk)} chars):")
        print(f"'{chunk}'")
    
    print(f"\nðŸ“Š NEW CHUNKING SUMMARY:")
    print(f"   â€¢ Total chunks: {len(new_chunks)}")
    print(f"   â€¢ Average chunk size: {sum(len(c) for c in new_chunks) // len(new_chunks)} chars")
    print(f"   â€¢ Largest chunk: {max(len(c) for c in new_chunks)} chars")
    
    # COMPARISON
    print(f"\nðŸŽ¯ IMPROVEMENT SUMMARY:")
    print(f"   â€¢ Old: {len(old_chunks)} large chunks (hard to read)")
    print(f"   â€¢ New: {len(new_chunks)} small chunks (easy to read)")
    print(f"   â€¢ Chunk size reduction: {800-200} characters smaller")
    print(f"   â€¢ Better searchability: âœ…")
    print(f"   â€¢ Contact info stays together: âœ…")
    print(f"   â€¢ Natural text boundaries: âœ…")

if __name__ == "__main__":
    test_old_vs_new_chunking() 